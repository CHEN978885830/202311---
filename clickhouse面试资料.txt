一、clickhouse：为什么不支持精准一次性
1、sink端实现事务
2、sink端实现幂等性
3、需要数据源可以回放数据
4、需要自己可以checkpoint
因为clickhouse是一个olap数据库，本身不支持事务，本质不支持delete和update数据，他只是把数据放入新的分区，再重新打标记删除

二、你提到了clickhouse做故障恢复，你们遇到了哪些故障如何恢复的
采用总分的方式去答题：
断电：
1、首先就是断电clickhouse无法启动，因为clickhouse本身有个参数叫做max_suspicious_broken_parts默认为10
2、因为我们有数据是通过kafka引擎导入clickhouse的，中间数据大量流入，中间会有后台会有很多合并操作，断电了，他可能就会有数据合并出现一些异常
3、遇到这种情况，首先我们要做的就是把机器起起来，首先如果是我们有复制表，有备份数据，那么我们会执行
sudo -u clickhouse touch /var/lib/clickhouse/flags/force_restore_data，其实他也是向zookeeper创建一个节点，去从复制表中恢复异常数据
4、如果这个方法不可行，那么我们尝试调大max_suspicious_broken_parts的值，这个值变大了，也可以把clickhouse起起来
5、如果还不行，就手动恢复，从日志中找到那个表格的uuid，找到这个表格所在的目录，里面会有很多Mutation文件，把这些mutation文件备份起来，重启
6、启动以后，对比他和hive表的数据，假如数据量相差较大，就重新将hive表的数据导入clickhouse中

mysql连接出现了问题，导致clickhouse无法重启
1、mysql引擎连不上了，导致clickhouse启动异常，找到那个mysql引擎对应的目录，把那个建表元数据目录删掉，然后重新建mysql引擎表
磁盘坏了
1、有副本表，保障重要数据不会丢失，如果异常了，就从副本表中恢复
2、一些较大的表格，就对比数据量，重新导数

磁盘满了
1、磁盘监控告警
单点并发过高问题，导致单点总是负载很高，会出现很多异常
1、对dolphinScheduler做了一个负载均衡
数据异常问题
一些重要数据建立副本表，有问题也好恢复

还有就是对一些执行时间长的sql进行定位，找到那条sql，对其进行优化，优化sql本身，或者优化执行频率

为什么要引入ck
1、因为hive数仓速度慢，查询任务多压力大
2、报表展示直接用hive速度慢报表显示数据速度太慢，用mysql需要则需要大量的数据同步
3、对于一些场景，mysql的计算实时性不高，有一些报表数据我们希望实时较为提供结果，clickhouse他有kafka引擎，也可以用定时任务做小批量的数据计算
4、es的分页性能比较差

为什么列式存储比行式存储快
1、列式存储可以很好的利用压缩算法，因为同一列数据通常具有较高的局部性和重复性
2、列式存储可以更好的支持olap，因为通常olap系统存储宽表大表居多，但是分析的时候只用到了某几列数据，列式存储避免了不必要的数据查询，提高了查询效率，提高了磁盘io
3、列式存储可以更好的支持向量化操作，当进行一系列数据操作时，列数据通常可以作为连续的、相同类型的数据块进行处理，这样可以使得 CPU 的向量指令更容易实现，从而提高并发度和运算速度。

什么是向量化操作
1、向量化操作是通过批量处理和并行计算来提高计算效率的一种技术，通常数据库需要单独处理，每一个数据元素，会消耗大量的时间资源，而向量化操作则是将需要数据元素组织成向量的形式，然后用基于向量的指令集硬件优化，
对整个数据进行向量操作，例如我们可以将一个多元方程转化成向量化的运算，向量化的运算可以利用cpu的向量指令集，提高计算效率


可以介绍一下clickhouse的索引机制吗：
clickhouse要求，每个MergeTree引擎表都有order by字段或者是primary字段，那个字段可以被理解成索引，数据都是有序的，索引是稀疏索引有一个index_granularity字段来标识稀疏索引的粒度。
我们还可以对clickhouse加上bitmap或者是跳数索引的两种索引

bitmap索引的原理是：
clickhouse每个列会划分为多个块，bitmap会给这个块的每个枚举值创建一个位数组，大小为块的数据量大小，哪一行有这个值，就哪一行置1
查询的时候，clickhouse会给把查询条件中的值找到这些bitmap，然后把这些值对应的bitmap做与运算，就知道每一个块应该取哪几行数据了

而跳数索引的原理是，希望clickhouse告诉我们哪些块是应该被跳过的：
跳数索引的类型也有很多，例如有set，有布隆滤波器，set，minmax等等
他有个索引粒度GRANULARITY，如果是2，相当于2倍的主键索引的粒度，即每2个主键索引的粒度建立一个跳数索引。
如果是set，他会为每个块，建立一个set，去存储那个set中的值，如果value不在set里面，就跳过这些块，不去扫描
如果是minMax，则会保存每个块的最大值，最小值，如果value不在这个范围里面，则不去扫描
如果是布隆滤波器，则会每个块有一个bit数组，每个数值插入的时候，会去经过一些hash函数，落了一些值在这个数组里面，当where查询的时候，我们也会把值经过这个hash函数，当value落到这个数组上的时候，全碰到1，则说明数据可能在这个数据块上，
则需要查询这个数据块

bitmap做有限范围内的数值快速排序
例如10以内的不重复数字
我们可以弄一个10位的数组，将对应位置的bit依次置1，再取出来即是有序的

clickhouse的二级索引，包括bitmap和跳数索引
bitmap是给某个列的每一个枚举值，都创建一个位

clickhouse的数据压缩：
LZ4和ZSTD，LZ4的压缩比14:1，ZSTD 速度更慢，但是压缩比更高

为什么没有用doris，是因为之前在接手这个的时候
从运维角度来看
clickhouse：1、clickhouse需要修改每个节点的配置，然后重启各个节点
doris：2、可以动态不停机新增结点

ck：数据不会自动负载均衡，需要手动导数
doris：数据会自动负载均衡，不用手动导数
ck：宕机会当数据异常会导致集群无法启动
doris：有label机制，可以在宕机以后，查看哪些任务是失败的，重新导数

使用角度
ck：mysql外表引擎，查询延迟很高，简单的查询都需要秒级响应，而且转化成sql
doris：mysql外表可以做到毫秒级响应，比clickhouse快很多
ck：导数没有容错机制，一但数据异常，就会导致整体任务失败，数据导了一半
doris：导数有label标签，是后台执行的，中间网络异常，可以检查label的执行结果，导数要么同时完成，要么同时失败

不支持高并发，doris支持高并发

在 ClickHouse 中常用的系统表有这些：
system.processes：该表显示了当前正在运行的 ClickHouse 进程的信息，包括运行的查询、进程 ID、线程 ID、执行时间、查询文本等。
system.metrics：该表提供了一系列 ClickHouse 集群和节点的性能指标，如 CPU 使用率、内存使用率、磁盘空间使用率等。
system.query_log：该表记录了最近执行的查询日志，包括查询的文本、执行开始时间、执行结束时间、耗时等。
system.replicas：该表显示了 ClickHouse 的分布式复制架构中的副本信息，包括表名、副本的 ID、副本所在的节点等。
system.parts：该表存储了分布式表的各个分区（分片）的元数据信息，包括表名、分区编号、分区的生命周期状态等。
system.mutations：该表包含有关正在执行或已完成的数据变更操作（如插入、更新、删除）的信息，以及它们对应的分布式表的分区信息。
